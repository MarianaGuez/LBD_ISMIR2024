# Background
  "You're Not You When You're Angry: Robust Emotion Features Emerge by Recognizing Speakers" is a paper by the authors: Zakaria Aldeneh, University of Michigan, Ann Arbor, MI, USA, and
Emily Mower Provost, University of Michigan, Ann Arbor, MI, USA. It explores through different experiments how embedding used for recognizing people's identities changes with emotional content.

This is a very interesting paper for exploring the field of emotion recognition. 

In this repository, I recreate one of their experiments to show the intuition behind the results.

# Late-Breaking Demo 

I recreate the experiments to analyze whether this phenomenon also occurs with instruments. The results show that it occurs, concluding that the embeddings used for recognizing people's identities (x-vectors) are a suitable feature for the emotion recognition task in music. 

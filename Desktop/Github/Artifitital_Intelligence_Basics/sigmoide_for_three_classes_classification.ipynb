{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h5ZOltE9x1s"
      },
      "source": [
        "Programa el algoritmo de retropropagación usando NumPy para una tarea de clasificación binaria, presuponiendo una red densa con dos capas ocultas y la función de perdida de entropía cruzada binaria. Describe las fórmulas y reglas de actualización de los pesos y sesgos de cada capa y entrena y evalúa la red en algún conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0chjGy1r7_O-"
      },
      "source": [
        "#1.-Añadir librerías:\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnITds9If73C"
      },
      "source": [
        "#2.- Función de activación\n",
        "def sigmoide(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "#Como se busca realizar una retropropagación, se requiere utilizar el gradiente, y necesitamos una función de activación que puede ser diferenciable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y12B10b0YBu1"
      },
      "source": [
        "def sigmoide_dos(z):\n",
        "    return 1 / (1 + np.exp(-z)) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S02_sySFgZZu"
      },
      "source": [
        "# Derivada de la función de activación para trabajar un backprop\n",
        "def derivada_sigmoide(x):\n",
        "    return np.multiply(sigmoide(x), (1.0 - sigmoide(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgmYUAnUjBiL"
      },
      "source": [
        "Note:\n",
        "The widespread saturation of sigmoidal units can make gradient-based learning very diﬃcult. For this reason, their use as hidden units in feedforward networks is now discouraged. Their use as output units is compatible with the use of gradient-based learning when an appropriate cost function can undo the saturation of the sigmoid in the output\n",
        "layer.\n",
        "\n",
        "The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice.\n",
        "\n",
        "The function is differentiable.That means, we can find the slope of the sigmoid curve at any two points.\n",
        "\n",
        "The function is monotonic but function’s derivative is not.\n",
        "\n",
        "The logistic sigmoid function can cause a neural network to get stuck at the training time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rODLiHElgnLX"
      },
      "source": [
        "# 3.- Función de pérdida:\n",
        "def entropia_cruzada_binaria(y, p):\n",
        "    p[p == 0] = np.nextafter(0., 1.)\n",
        "    p[p == 1] = np.nextafter(1., 0.)\n",
        "    return -(np.log(p[y == 1]).sum() + np.log(1 - p[y == 0]).sum())   #fórmula de la entrópia binaria cruzada\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OdcglA_17l_"
      },
      "source": [
        "La función de pérdida por entropía cruzada, determina que tan diferente es la distribución aproximada con la verdadera.\n",
        "\n",
        "Nota: nextafter es una función que regresa el siguiente valor flotante en el primer caso en dirrección 0 a 1, y determina el valor de probabilidad que nuestra entrada corresponda a la clase 0, en el segundo caso busca el flotante más cercano en dirreción de 1 a 0 (el número flotante va disminuyendo) ésta corresponde a la probabilidad de que nuestra entrada no sea de la clase 0 (en nuestro caso, que pertenezca a la clase 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu7HGy31lr2b"
      },
      "source": [
        "# 4.- Exactitud:\n",
        "def exactitud(y, y_predicha):\n",
        "    return (y == y_predicha).mean() * 100   #Correctos/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYtfNDySdmUQ"
      },
      "source": [
        "def exactitud2(y, y_predicha):\n",
        "\n",
        "  y_hat = np.zeros(y.shape[0])\n",
        "  for i in range(y.shape[0]):\n",
        "    if (y[i] == y_predicha[i]):\n",
        "      y_hat[i] = 1\n",
        "    else:\n",
        "      y_hat[i] = 0\n",
        "\n",
        "  return (y_hat).mean() * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgFzQKv67wOK"
      },
      "source": [
        "# 5.- Feedforward:\n",
        "\n",
        "def Estimar_Entradas(x, W1, b1, W2, b2, W3, b3):\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    a2 = (a1) * W2 + b2\n",
        "    H2 = sigmoide(a2)\n",
        "    y_hat = sigmoide(np.dot(H2, W3) + b3)\n",
        "\n",
        "    return y_hat, H2, a2, a1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOl245vSlbvz"
      },
      "source": [
        "def Segunda_adelante(x, W4, b4):\n",
        "    return sigmoide_dos(np.dot(x, W4) + b4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YdbLHdg9ekb"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    s = sigmoid(x)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def binary_crossentropy(y_true, y_pred):\n",
        "    eps = 1e-10\n",
        "    return -np.mean(y_true * np.log(y_pred + eps) +\n",
        "                    (1 - y_true) * np.log(1 - y_pred + eps))\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == np.round(y_pred)) * 100\n",
        "\n",
        "def forward_layer(X, W, b):\n",
        "    z = np.dot(X, W) + b\n",
        "    return sigmoid(z), z\n",
        "\n",
        "def forward_stage1(x, params):\n",
        "    a1, z1 = forward_layer(x, params['W1'], params['b1'])\n",
        "    a2, z2 = forward_layer(a1, params['W2'], params['b2'])\n",
        "    phi = np.dot(a2, params['W3']) + params['b3']\n",
        "    return phi, a1, z1, a2, z2\n",
        "\n",
        "def forward_classifier(x, W, b):\n",
        "    return sigmoid(np.dot(x, W) + b)\n",
        "\n",
        "def init_params(input_dim, hidden_dim, phi_dim, out_dim):\n",
        "    params = {\n",
        "        'W1': np.random.randn(input_dim, hidden_dim) * np.sqrt(1 / input_dim),\n",
        "        'b1': np.zeros((1, hidden_dim)),\n",
        "\n",
        "        'W2': np.random.randn(hidden_dim, hidden_dim) * np.sqrt(1 / hidden_dim),\n",
        "        'b2': np.zeros((1, hidden_dim)),\n",
        "\n",
        "        'W3': np.random.randn(hidden_dim, phi_dim) * np.sqrt(1 / hidden_dim),\n",
        "        'b3': np.zeros((1, phi_dim)),\n",
        "\n",
        "        'W4': np.random.randn(phi_dim, out_dim) * np.sqrt(1 / phi_dim),\n",
        "        'b4': np.zeros((1, out_dim)),\n",
        "\n",
        "        'W5': np.random.randn(phi_dim, out_dim) * np.sqrt(1 / phi_dim),\n",
        "        'b5': np.zeros((1, out_dim))\n",
        "    }\n",
        "    return params\n",
        "\n",
        "\n",
        "\n",
        "def train_model(X, Phi_target, y1_target, y2_target, lr, epochs, hidden_dim):\n",
        "\n",
        "    n_samples, input_dim = X.shape\n",
        "    phi_dim = Phi_target.shape[1]\n",
        "    out_dim = y1_target.shape[1]\n",
        "\n",
        "    params = init_params(input_dim, hidden_dim, phi_dim, out_dim)\n",
        "\n",
        "    # Buffers\n",
        "    Phi_pred = np.zeros_like(Phi_target)\n",
        "    Y1_pred = np.zeros_like(y1_target)\n",
        "    Y2_pred = np.zeros_like(y2_target)\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(n_samples):\n",
        "\n",
        "            phi, a1, z1, a2, z2 = forward_stage1(X[i], params)\n",
        "\n",
        "            # Gradients - Stage 1\n",
        "            dphi = phi - Phi_target[i]\n",
        "\n",
        "            dW3 = np.dot(a2.T, dphi)\n",
        "            db3 = dphi\n",
        "\n",
        "            dH2 = np.dot(dphi, params['W3'].T) * sigmoid_derivative(z2)\n",
        "            dW2 = np.dot(a1.T.reshape(-1,1), dH2)\n",
        "            db2 = dH2\n",
        "\n",
        "            dH1 = np.dot(dH2, params['W2'].T) * sigmoid_derivative(z1)\n",
        "            dW1 = np.dot(X[i].reshape(-1,1), dH1)\n",
        "            db1 = dH1\n",
        "\n",
        "            # Update\n",
        "            for W, dW in zip(['W1','W2','W3'], [dW1, dW2, dW3]):\n",
        "                params[W] -= lr * dW\n",
        "            for b, db in zip(['b1','b2','b3'], [db1, db2, db3]):\n",
        "                params[b] -= lr * db\n",
        "\n",
        "            Phi_pred[i] = phi\n",
        "\n",
        "        loss = binary_crossentropy(Phi_target, Phi_pred)\n",
        "        acc = accuracy(Phi_target, Phi_pred)\n",
        "\n",
        "        print(f\"[Stage 1] Epoch {epoch} - Loss: {loss:.4f} Acc: {acc:.1f}%\")\n",
        "\n",
        "        if acc == 100:\n",
        "            Entradas = np.round(Phi_pred)\n",
        "            break\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(n_samples):\n",
        "\n",
        "            y1 = forward_classifier(Entradas[i], params['W4'], params['b4'])\n",
        "            y2 = forward_classifier(Entradas[i], params['W5'], params['b5'])\n",
        "\n",
        "            # Gradients Stage 2\n",
        "            dy1 = y1 - y1_target[i]\n",
        "            dy2 = y2 - y2_target[i]\n",
        "\n",
        "            params['W4'] -= lr * np.dot(Entradas[i].reshape(-1,1), dy1)\n",
        "            params['b4'] -= lr * dy1\n",
        "\n",
        "            params['W5'] -= lr * np.dot(Entradas[i].reshape(-1,1), dy2)\n",
        "            params['b5'] -= lr * dy2\n",
        "\n",
        "            Y1_pred[i] = y1\n",
        "            Y2_pred[i] = y2\n",
        "\n",
        "        loss1 = binary_crossentropy(y1_target, Y1_pred)\n",
        "        acc1 = accuracy(y1_target, Y1_pred)\n",
        "\n",
        "        loss2 = binary_crossentropy(y2_target, Y2_pred)\n",
        "        acc2 = accuracy(y2_target, Y2_pred)\n",
        "\n",
        "        print(f\"[Stage 2] Epoch {epoch} - Loss1: {loss1:.4f} Acc1: {acc1:.1f}%\" )\n",
        "        print(f\"[Stage 2] Epoch {epoch} - Loss2: {loss2:.4f} Acc2: {acc2:.1f}%\" )\n",
        "\n",
        "        if acc1 == 100 and acc2 == 100:\n",
        "            print(\"\\nPrediction Y1:\\n\", np.round(Y1_pred))\n",
        "            print(\"\\nPrediction Y2:\\n\", np.round(Y2_pred))\n",
        "            break\n",
        "\n",
        "    return params\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h44OorQLCKFz"
      },
      "source": [
        "X = np.array([[0, 0], [0, 1], [1,0], [1,1]])\n",
        "Phi_target = np.array([[0, 0, 0, 1],[0, 1, 1, 0]]).T\n",
        "y_target = np.array([[1, 1, 1, 2]]).T\n",
        "y_target2 = np.array([[0, 1, 1, 1]]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToGE70GFCNrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db475471-7bcc-43f3-a26e-2c5daa9743fb"
      },
      "source": [
        "#Sumador de dos bits con resultado en decimal:\n",
        "W1, b1, W2, b2, W3, b3, W4, b4 = retropropagacion(X, Phi_target, y_target, .5, 100, 10)\n",
        "\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 0: Error = 6.948298279448793 Exactitud: 50.0\n",
            "Epoca 1: Error = 6.870571020781195 Exactitud: 62.5\n",
            "Epoca 2: Error = 6.7336478639267545 Exactitud: 62.5\n",
            "Epoca 3: Error = 6.589001924637884 Exactitud: 62.5\n",
            "Epoca 4: Error = 6.455620050539748 Exactitud: 62.5\n",
            "Epoca 5: Error = 6.334047127600248 Exactitud: 62.5\n",
            "Epoca 6: Error = 6.221887334299726 Exactitud: 62.5\n",
            "Epoca 7: Error = 6.116729735177984 Exactitud: 62.5\n",
            "Epoca 8: Error = 6.01661858475369 Exactitud: 62.5\n",
            "Epoca 9: Error = 5.9200531860309145 Exactitud: 62.5\n",
            "Epoca 10: Error = 5.825913444380527 Exactitud: 62.5\n",
            "Epoca 11: Error = 5.733398039766715 Exactitud: 62.5\n",
            "Epoca 12: Error = 5.641989534905204 Exactitud: 50.0\n",
            "Epoca 13: Error = 5.5514390423382824 Exactitud: 50.0\n",
            "Epoca 14: Error = 5.461753779837109 Exactitud: 50.0\n",
            "Epoca 15: Error = 5.373168343971043 Exactitud: 50.0\n",
            "Epoca 16: Error = 5.286087338402624 Exactitud: 50.0\n",
            "Epoca 17: Error = 5.20100225140507 Exactitud: 50.0\n",
            "Epoca 18: Error = 5.1184001386695535 Exactitud: 50.0\n",
            "Epoca 19: Error = 5.038684978952172 Exactitud: 50.0\n",
            "Epoca 20: Error = 4.962124213453009 Exactitud: 50.0\n",
            "Epoca 21: Error = 4.888823394896203 Exactitud: 37.5\n",
            "Epoca 22: Error = 4.818728284964697 Exactitud: 37.5\n",
            "Epoca 23: Error = 4.751652504464019 Exactitud: 37.5\n",
            "Epoca 24: Error = 4.687324248541234 Exactitud: 37.5\n",
            "Epoca 25: Error = 4.625439261950641 Exactitud: 50.0\n",
            "Epoca 26: Error = 4.565704925216863 Exactitud: 50.0\n",
            "Epoca 27: Error = 4.507863817948634 Exactitud: 50.0\n",
            "Epoca 28: Error = 4.451691588899189 Exactitud: 50.0\n",
            "Epoca 29: Error = 4.3969698716709615 Exactitud: 50.0\n",
            "Epoca 30: Error = 4.343438804084396 Exactitud: 50.0\n",
            "Epoca 31: Error = 4.2907354192406615 Exactitud: 50.0\n",
            "Epoca 32: Error = 4.238324343004296 Exactitud: 50.0\n",
            "Epoca 33: Error = 4.185427020519777 Exactitud: 50.0\n",
            "Epoca 34: Error = 4.130957047145717 Exactitud: 50.0\n",
            "Epoca 35: Error = 4.0734735408448035 Exactitud: 50.0\n",
            "Epoca 36: Error = 4.011169977183812 Exactitud: 50.0\n",
            "Epoca 37: Error = 3.941917750408761 Exactitud: 50.0\n",
            "Epoca 38: Error = 3.863385530971194 Exactitud: 50.0\n",
            "Epoca 39: Error = 3.773279551537501 Exactitud: 50.0\n",
            "Epoca 40: Error = 3.6697956240616314 Exactitud: 50.0\n",
            "Epoca 41: Error = 3.5523186495272796 Exactitud: 62.5\n",
            "Epoca 42: Error = 3.422076436996516 Exactitud: 62.5\n",
            "Epoca 43: Error = 3.282078383371123 Exactitud: 62.5\n",
            "Epoca 44: Error = 3.1359940910264497 Exactitud: 62.5\n",
            "Epoca 45: Error = 2.986697930978531 Exactitud: 75.0\n",
            "Epoca 46: Error = 2.8356029301257126 Exactitud: 87.5\n",
            "Epoca 47: Error = 2.6830110202883253 Exactitud: 87.5\n",
            "Epoca 48: Error = 2.528918639152457 Exactitud: 100.0\n",
            "Epoca 49: Error = 2.3737815168171794 Exactitud: 100.0\n",
            "Epoca 50: Error = 2.2189951250121522 Exactitud: 100.0\n",
            "Epoca 51: Error = 2.066934872649872 Exactitud: 100.0\n",
            "Epoca 52: Error = 1.9205172127680057 Exactitud: 100.0\n",
            "Epoca 53: Error = 1.7824841361961616 Exactitud: 100.0\n",
            "Epoca 54: Error = 1.6547853622331505 Exactitud: 100.0\n",
            "Epoca 55: Error = 1.5383313769987068 Exactitud: 100.0\n",
            "Epoca 56: Error = 1.4331136054236875 Exactitud: 100.0\n",
            "Epoca 57: Error = 1.3385042888652932 Exactitud: 100.0\n",
            "Epoca 58: Error = 1.2535564249446294 Exactitud: 100.0\n",
            "Epoca 59: Error = 1.17722062412244 Exactitud: 100.0\n",
            "Epoca 60: Error = 1.1084723825634166 Exactitud: 100.0\n",
            "Epoca 61: Error = 1.0463736839150617 Exactitud: 100.0\n",
            "Epoca 62: Error = 0.990094895566526 Exactitud: 100.0\n",
            "Epoca 63: Error = 0.9389157049989505 Exactitud: 100.0\n",
            "Epoca 64: Error = 0.8922164365848423 Exactitud: 100.0\n",
            "Epoca 65: Error = 0.849465908241965 Exactitud: 100.0\n",
            "Epoca 66: Error = 0.8102088875446892 Exactitud: 100.0\n",
            "Epoca 67: Error = 0.7740545087683284 Exactitud: 100.0\n",
            "Epoca 68: Error = 0.7406661398268866 Exactitud: 100.0\n",
            "Epoca 69: Error = 0.7097527678642497 Exactitud: 100.0\n",
            "Epoca 70: Error = 0.6810617881751726 Exactitud: 100.0\n",
            "Epoca 71: Error = 0.6543730151841767 Exactitud: 100.0\n",
            "Epoca 72: Error = 0.6294937243697274 Exactitud: 100.0\n",
            "Epoca 73: Error = 0.6062545486165013 Exactitud: 100.0\n",
            "Epoca 74: Error = 0.584506075835651 Exactitud: 100.0\n",
            "Epoca 75: Error = 0.5641160193943987 Exactitud: 100.0\n",
            "Epoca 76: Error = 0.5449668557062931 Exactitud: 100.0\n",
            "Epoca 77: Error = 0.5269538430826968 Exactitud: 100.0\n",
            "Epoca 78: Error = 0.509983352446945 Exactitud: 100.0\n",
            "Epoca 79: Error = 0.49397145400958153 Exactitud: 100.0\n",
            "Epoca 80: Error = 0.4788427148997197 Exactitud: 100.0\n",
            "Epoca 81: Error = 0.46452917147545425 Exactitud: 100.0\n",
            "Epoca 82: Error = 0.4509694469960838 Exactitud: 100.0\n",
            "Epoca 83: Error = 0.4381079908783854 Exactitud: 100.0\n",
            "Epoca 84: Error = 0.4258944201683439 Exactitud: 100.0\n",
            "Epoca 85: Error = 0.41428294737471194 Exactitud: 100.0\n",
            "Epoca 86: Error = 0.4032318816206377 Exactitud: 100.0\n",
            "Epoca 87: Error = 0.39270319232417406 Exactitud: 100.0\n",
            "Epoca 88: Error = 0.3826621264354921 Exactitud: 100.0\n",
            "Epoca 89: Error = 0.37307687173030585 Exactitud: 100.0\n",
            "Epoca 90: Error = 0.3639182598572973 Exactitud: 100.0\n",
            "Epoca 91: Error = 0.3551595038183544 Exactitud: 100.0\n",
            "Epoca 92: Error = 0.3467759653681127 Exactitud: 100.0\n",
            "Epoca 93: Error = 0.3387449484877829 Exactitud: 100.0\n",
            "Epoca 94: Error = 0.33104551564462886 Exactitud: 100.0\n",
            "Epoca 95: Error = 0.32365832401379746 Exactitud: 100.0\n",
            "Epoca 96: Error = 0.3165654792303473 Exactitud: 100.0\n",
            "Epoca 97: Error = 0.3097504045696119 Exactitud: 100.0\n",
            "Epoca 98: Error = 0.3031977237340772 Exactitud: 100.0\n",
            "Epoca 99: Error = 0.296893155663439 Exactitud: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtDPV_z_nNJR"
      },
      "source": [
        "def phi (x, W1, b1, W2, b2, W3, b3):\n",
        "    return np.round(sigmoide(np.dot((sigmoide((np.dot(x, W1) + b1)* W2 + b2)), W3) + b3))"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y69L1de9T7U",
        "outputId": "79046b44-f07e-47de-932d-26a4f09118d3"
      },
      "source": [
        "bit_1 = 1\n",
        "bit_2 = 1\n",
        "\n",
        "phi_x = phi([bit_1, bit_2], W1, b1, W2, b2, W3, b3)\n",
        "\n",
        "suma = np.round(sigmoide_dos(np.dot(phi_x, W4) + b4))\n",
        "suma2 = np.round(sigmoide(np.dot(phi_x, W4) + b4))\n",
        "suma3 = np.round((np.dot(phi_x, W4) + b4))\n",
        "\n",
        "print(suma3)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXdwlz_aERvS",
        "outputId": "ad8dfd5d-8c61-492d-a03d-fa338f21ddbb"
      },
      "source": [
        "y = np.round(sigmoide(np.dot(sigmoide(((np.dot([1, 0], W1)+b1)*W2)+b2),W3)+b3))\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2Nad98N-8Re",
        "outputId": "c39aa9c0-2426-4ebc-a46c-f37abc2a1cf6"
      },
      "source": [
        "print(W4)\n",
        "print(b4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.65219534]\n",
            " [ 5.21475299]]\n",
            "[[0.06344762]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl6S1s0629Nm",
        "outputId": "ab1b9574-b41f-462b-e293-1e9239091a3a"
      },
      "source": [
        "y = np.round(sigmoide(np.dot([1, 1], W4)+b4))\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gf1O3Rm3OtM"
      },
      "source": [
        "for i in range(Epocas):\n",
        "        for k in range(0, 3, 1):\n",
        "            y_entrada = np.round(sigmoide(np.dot(sigmoide(((np.dot(X[k+1], W1)+b1)*W2)+b2),W3)+b3))\n",
        "            y_hat2 = Segunda_adelante(y_entrada, W4, b4)\n",
        "\n",
        "            db4 = y_hat2 - y_out[k]\n",
        "            dw4 = np.dot(y_entrada.T, db4)\n",
        "\n",
        "            W4 = W4 - alpha * dw4\n",
        "            b4 = b4 - alpha * db4\n",
        "            Activacion(y_hat2)\n",
        "            y_predicha[k+1] = y_hat2\n",
        "            print(y_predicha[k+1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}